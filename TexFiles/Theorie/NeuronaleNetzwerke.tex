\section{Neuronale Netzwerke}
\label{sec:NN}
Hier Aufbereitung, Anreicherung und Übersetzung von Selby \cite{SelbyNN}!
\subsection{Modell künstlicher neuronalen Netzen}
\paragraph{Historisches Konzept}
Hier sagen, wie das mit dem Gehirn zusammen hängt, woher kommt der Name und warum  spricht man heute von künstlichen NN
\paragraph{Aufbau des Modells}
Klassisches Bild mit Input-Layers, Hidden Layers, Output Layers

Bezug auf Logistische und Lineare Regression, das diese NN ohne Hidden Layers sind

Zuordnung der Begriffe?
\subsection{Hidden Layers}
Wie wird das Modell der logistischen Regression erweitert?

Deep Learning = Mehr als 1 Hidden Layer

Manchmal: Deep Learning = Unsupervised Learning + viele Hidden Layers
\subsection{Forward Propagation}
Reinschmeißen eines Trainingsbeispiels und messen, wie schlimm es daneben liegt bzw. ob es daneben liegt
\subsection{Backward Propagation}
Nach dem Forward-Prograpagation nachjustieren der Gewichte in Matrix

Optimierungsfunktion und Gewichte
\subsection{Training}
Wie geht Training allgemein 

worauf muss man bei Trainingsdaten achten, welche Größenordnungen sind notwendig

Anmerkung zu teilweise Export des Modells
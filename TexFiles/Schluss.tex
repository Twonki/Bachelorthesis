\chapter{Fazit}
\label{cha:Fazit} \label{cha:Schluss}
Im Rahmen der Arbeit haben sich verschiedene, übergreifende Ergebnisse herauskristallisiert welche nun abschließend aufbereitet werden.

~\newline In Bezug auf die Benutzung der Algorithmen gilt: \textit{\textbf{Easy to learn, hard to master}}. 

~\newline Moderne Frameworks und Bibliotheken ermöglichen es \textit{kinderleicht} komplexe Modelle zu erstellen und zu benutzen. Sogar die Aufbereitung der Daten erfolgt einfach mithilfe optischer Werkzeuge oder wird sogar automatisch übernommen (z.B. die Normierung und Faktorisierung innerhalb von RevoScaler).

~\newline Dennoch liefern diese Modelle nicht unbedingt zufriedenstellende Ergebnisse: 

Entweder sind die Standard-Einstellungen nicht geeignet, oder die Aufbereitung der Daten produziert neue Fehler (z.B. wenn die Orte als ID übergeben werden, sind diese nicht faktorisiert). Auch entstehen häufig Fehler bei automatisch faktorisierten Daten, etwa weil innerhalb der Trainingsmenge eien Merkmalsausprägung gefehlt hat, welche in den Testdaten vorkommt und nicht korrekt auf den Eingabevektor übertragen werden kann. 

Fehler dieser Art zeigen sich erst bei der konkreten Anwendung des Modells auf separate Testdaten: Werden die \textit{korrumpierten} Trainingsdaten und Einstellungen in Standardeinstellungen verwendet, so zeigt das Modell bei zunehmenden Training ebenfalls Erfolg - es spiegelt nur nicht zwangsläufig echte Erfolge wieder.

~\newline Insofern sind die Frameworks und Standardeinstellungen zwar angenehm für den Einstieg, sollten allerdings für die Umsetzung eines Projektes genau inspiziert werden. Vor allem die Aufbereitung der Trainingsdaten und die Kontrolle des Modells sollte der Entwickler selbst übernehmen.  

~\newline Ein häufiger Satz, welcher v.A. in Internetforen auftritt, ist \textit{\textbf{building neural networks is more art than science}}.

Diesen Satz sollte man nicht unreflektiert hinnehmen - viele Änderungen, Designentscheidungen und Trainingserfolge wurden bewusst durch die wissenschaftlichen Eigenschaften der einzelnen Komponenten erzielt. 

~\newline  Konkret zeigte sich dies bei der Benutzung der $tanh$-Funktion gegenüber der Sigmoid-Funktion in Abschnitt \ref{sec:RidesPred} welche Aufgrund ihrer Eigenschaften mit negativen Werten bessere Ergebnisse erzielte. 

~\newline Auch ist die Analyse des Datenbestandes, im Speziellen die Suche nach Anomalien, und das Design von Features im Bereich der Wissenschaft anzusiedeln. 

~\newline Zwar sind viele Fortschritte, z.B. das beheben von Over- und Underfitting, experimentell entstanden, dennoch können 
grundlegende Probleme auftreten, welche sich nicht (zeitnah) experimentell lösen lassen, im Rahmen dieser Arbeit konkret Abschnitt \ref{sec:RevPred} zur Schätzung des Umsatzes und \ref{sec:PasPred} für das Passagieraufkommen. Hier haben selbst umfangreiche Experimente keine Ergebnisse erzielt.

~\newline  Als letzter, großer Themenblock \textit{pro science} ist ebenfalls das Performancetuning zu nennen: 

Alle Hyperparameter der Optimierungsfunktion haben einen technischen Ursprung, und ein Verständnis der Algorithmen ist notwendig, um die Parameter sinnvoll zu wählen. Zwar sind die Standardeinstellungen hier meistens hinreichend, allerdings können durch bewusste Anpassung ebenfalls markante Besserungen in der Trainingsgeschwindigkeit erzielt werden. 

So zeigten höhere Lern- und Verfalls-Parameter bei den weitestgehend homogenen Trinkgelddaten ein wesentlich schnelleres Terminieren das Trainings bei gleichbleibender Genauigkeit. 

Für andere Experimente, z.B. dem Fahrtenaufkommen, zeigten diese Einstellungen katastrophale Ergebnisse - die Daten waren einfach zu verschieden, um mit diesen Parametern behandelt zu werden. 

~\newline Große Teile sind allerdings rein experimentell - vor Allem die optimale Größe der einzelnen Hidden Layer zu finden gestaltet sich im Wesentlichen durch Versuche.

~\newline Insgesamt kann zwar jedes Problem rein experimentell gelöst werden, allerdings stellt dies oft mehr einen \textit{Glückstreffer} dar. 

Ein Verständnis der Algorithmen, ihrer Eigenschaften und der verwendeten Funktionen ermöglicht nicht nur eine bessere Ausgangslage für das Tuning, sondern ist eine Grundvoraussetzung für die Fehleranalyse und Problembehebung. 

~\newline Insofern ist der Ansatz, die Herangehensweise \textit{a priori} als Kunst zu bezeichnen nicht gerechtfertigt. Die Arbeit mit neuronalen Netzen entpuppte sich als gesunde Mischung aus Kunst und Wissenschaft. 

\paragraph{Ausblick}~\newline Innerhalb der Arbeit ließen sich zwei weiterführende Themen ausmachen: 

Der Fokus auf Alternativen bei der Umsatzprognose sowie die Übertragung und Verallgemeinerung der erarbeiteten Netze. Diese beiden Ansätze werden kurz ausgearbeitet. 

~\newline Die Umsatzprognose stellt nach wie vor den wichtigsten Use-Case für viele Unternehmen dar, und konnte ihm Rahmen dieser Arbeit mit neuronalen Netzen nicht gelöst werden. Im Zuge einer weiteren Arbeit kann der Hauptfokus auf der Umsatzprognose liegen, und verschiedene Formen der Vorhersage benutzt und verglichen werden um Ergebnisse zu erzielen. 

Möglichkeiten stellen hierbei klassische statistische Methoden dar, oder eine Vertiefung anderer technischer Ansätze wie etwa Timeseries-Datenbanken oder Modellierung innerhalb einer Mehrdimensionalen-Datenbank.

~\newline Ein weiterer Punkt ist die Portierung der in dieser Arbeit erzeugten neuronalen Netze auf ähnliche Anwendungsgebiete, konkreter auf Taxidaten einer anderen Stadt. 

Hierbei zu lösen sind Schwierigkeiten bezüglich unterschiedlicher Eingabevektoren, vergleichbare Tests zu erzeugen sowie die technische Umsetzung innerhalb des SQL-Servers.  
\newpage
\label{Prognosen}
\section{Trinkgeldprognose}
\label{sec:TipPred}
Als erstes Beispiel wird die Vorhersage des gegebenen Trinkgeldes behandelt. 

~\newline Dies stellt zwar nicht unbedingt ein für das Unternehmen hochgradig relevantes Thema dar, bietet jedoch einen guten Einstieg in das Thema Regression mit Hilfe von \textit{Deep Learning}:

~\newline Es ist anzunehmen, dass Passagiere nach einem gewissen Schema Trinkgeld geben, etwa um Beträge aufzurunden oder eine schnelle Fahrt zu \textit{belohnen}. Ebenso kann es Kriterien geben, welche nicht innerhalb der Daten erfasst sind, wie die Stimmung der Passagiere oder die Freundlichkeit des Fahrers. Genauso treten eventuell Kriterien auf, welche zu einem Entfall des Trinkgeldes führen, eine lange Fahrt, eine Panne, oder ein Taxifahrer der \textit{Extrarunden dreht}. 

~\newline Dennoch lassen sich diese potenziellen Kriterien schwer in einen anwendbaren Katalog zusammenfassen, nachdem man logisch das Trinkgeld erschließen kann. Vor diesem Hintergrund bietet sich die Verwendung eines tiefen Neuronalen Netzes an: 

Die erste versteckte Schicht extrahiert (uns unbekannte, nicht genauer definierte) Kriterien automatisch, und die zweite Schicht gewichtet diese. 
\paragraph{Zielsetzung} ~\newline
Das Modell soll vorhersagbare Attribute erhalten, um für eine geplante Fahrt das Trinkgeld zu schätzen. 

Ziel ist es eine gute Prognose mit realistischen, d.h. abschätzbaren Features zu erzeugen. 

~\newline Aus unternehmerisches Sicht ist dieser Use-Case relevant, da Fahrer voraussichtlich die Fahrten mit höherem Trinkgeld bevorzugen werden, obwohl sich diese nicht mit dem größten Nutzen des Unternehmens decken müssen. 
\paragraph{Versuchsaufbau} ~\newline
Die Fahrten liegen in gefilterter, aber nicht weiter aufbereiteter Form vor. 

Als Eingabefeatures werden die Fahrtdauer in Minuten, der Start- und Ziel-Ort, die Kosten der Fahrt, die gefahrene Strecke und die Anzahl der Passagiere gewählt. 

Die Ausgabe ist eine Schätzung des Trinkgeldes in Dollar.
\paragraph{Netzaufbau und Einstellungen} ~\newline
Das neuronale Netz wurde mit zwei Schichten á 100 Knoten definiert. Die Schichten sind vollvermascht und verwenden beide die Sigmoidfunktion. Als Ausgabefunktion wurde \textit{Linear} gewählt.

~\newline Die Lernrate wurde auf 5\% gesetzt und als Optimierungsfunktion Stochastic Gradient Descent gewählt. Es werden jeweils 500 Epochen durchgeführt. 
\paragraph{Tuning und Verbesserung} ~\newline
Wesentliche Unterschiede in der Genauigkeit dieses Beispiels verbucht die Auswahl der Features:
\begin{itemize}
	\item Modelle, welche nicht die Gesamtkosten der Fahrt als Eingabe erhalten, erzielen nur Genauigkeiten von 75\%.
	\item Ein Modell, welches sich auf ausschließlich die Kosten der Fahrt stützt, erzielte eine Genauigkeit von ca. 40\%. 
	\item Werden die im Versuchsaufbau genannten Features um (grobe) Wetterdaten und eine Tageszeit erweitert, verbessert sich die Genauigkeit des Modells auf bis zu 98\%. 
	\item Werden die im Versuchsaufbau genannten Features um die Passagieranzahl gekürzt wird nur eine Genauigkeit von ca. 80\% erzielt - die Passagieranzahl scheint also ein wesentliches Feature darzustellen.
	\item Weitere Features, welche sich auf den Preis beziehen (z.B. die Rate der Fahrt, Steuerliche Zulagen, diverse Aufschläge), welche bereits im Gesamtpreis enthalten sind, bringen keine Veränderung der Genauigkeit. 
\end{itemize} 
~\newline Im Rahmen der Zielsetzung wurden aber lediglich die unter dem Versuchsaufbau gewählten Attribute verwendet. Die Vorhersage des Wetters gestaltet sich weitestgehend schwierig für ein Taxiunternehmen bzw. den Fahrer. 

~\newline Weitere Unterschiede erzeugten Veränderungen in der Netzdefinition: 

Eine Verkleinerung einer der beiden Schichten unter 50 Knoten führte zu drastisch schlechteren Ergebnissen (max. 60\% Genauigkeit). 

Eine Vergrößerung der Schichten über 100 Knoten führte zu keinem Gewinn an Genauigkeit, jedoch zu längeren Laufzeiten (Ein Trainingsdurchlauf mit je 200 Knoten dauert ca. 4 mal so lange).

~\newline Eine Verwendung der Aktivierungsfunktion \textit{tanh} führte zu keinen Unterschieden, eine Verwendung der Softmax-Aktivierungsfunktion führte zu einer um ca. 20\% längeren Laufzeit und ähnlichen Genauigkeiten. 
\paragraph{Ergebnisse} ~\newline
Die folgenden Ergebnisse wurden mithilfe der unter \textbf{Netzaufbau und Einstellungen} genannten Optionen erzielt:

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=0.95\linewidth]{Bilder/TrinkgeldErgebnisse}
		\caption[Ergebnisse der Trinkgeldprognose]{Ergebnisse der Trinkgeldprognose}
		\label{fig:TipErg}
	\end{center}
\end{figure}

\todo{"Minifazit" hier? Kurze bewertung oder einfach so stehen lassen?}
\newpage
\section{Ratenerkennung}
\label{sec:RatePred}
Als zweites Beispiel wird die Erkennung der Fahrrate behandelt. Dieser Fall ist weitestgehend Trivial, wurde dennoch als einfache Referenz für Multiklassen-Klassifikation aufgenommen. 

~\newline Im Gegensatz zur Trinkgeldprognose sind die Kriterien, nach welchen sich die Fahrtkosten berechnen, klar dokumentiert: Je nach Rate kostet jede Meile und jede Minute einen bestimmten Betrag. Zusätzlich kommt je nach Gebiet (z.B. JFK-Airport) ein Aufschlag hinzu. Dahingehend lässt sich diese Formel zur Erkennung der Rate umformen.

~\newline Interessant wird dieser Use-Case vor dem Hintergrund, das die Raten bzw. ihre zugehörigen Verrechnungssätze nicht innerhalb der Daten auftreten, und das Modell erkennen muss, welche Beträge Aufschläge sind, und welche Beträge die Raten ausmachen. 

Das Modell soll also in diesem Fall einen für den Menschen eindeutigen, klar nachvollziehbaren Sachverhalt reproduzieren. 
\paragraph{Versuchsaufbau} ~\newline
Die Fahrten liegen in gefilterter, aber nicht weiter aufbereiteter Form vor. 

Als Eingabefeatures werden die Fahrtdauer in Minuten, der Start- und Ziel-Ort, die Kosten der Fahrt, die gefahrene Strecke sowie die Anzahl der Passagiere gewählt. 

Die Ausgabe ist die Rate der Taxifahrt als Dictionary-ID.
\paragraph{Netzdefinition} ~\newline
Das neuronale Netz wurde mit zwei Schichten á 100 Knoten definiert. Die Schichten sind vollvermascht und verwenden beide die Sigmoidfunktion. Als Ausgabefunktion wurde \textit{Softmax} gewählt.

~\newline Die Lernrate wurde auf 5\% gesetzt und als Optimierungsfunktion Stochastic Gradient Descent gewählt. Es werden jeweils 250 Epochen durchgeführt. 
\paragraph{Tuning und Verbesserung} ~\newline
Innerhalb der Ratenerkennung ließen sich wenig Verbesserungen vornehmen: Grund hierfür ist die bereits anfänglich hohe Genauigkeit. 

Eine Verbesserung der Geschwindigkeit lässt sich mit einem kleineren Netz erzielen. Eine Netzdefinition mit 60 und 10 Knoten in den Hidden Layern erzielte bei größeren Trainingsmengen ebenfalls eine Genauigkeit von 99\%, was für die meisten Anwendungen ausreichend ist. Es benötigt allerdings nur ca. ein Fünftel der Zeit fürs Training.
\paragraph{Ergebnisse} ~\newline
Die unter Netzdefinition genannten Optionen erzielten folgende Werte:

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=0.95\linewidth]{Bilder/RatenErgebnisse}
		\caption[Ergebnisse der Trinkgeldprognose]{Ergebnisse der Ratenerkennung}
		\label{fig:RateErg}
	\end{center}
\end{figure}

~\newline Ein wichtiges Teilergebnis ist die Veränderung des ersten Versuches mit 1000 Trainingsdaten zu dem mit 5000 Trainingsdaten: 
~\newline Zwar steigt die Genauigkeit nur minimal, dennoch werden erst ab 5000 Trainingsdaten die weniger vertretenen Daten korrekt erkannt. Das Modell für 1000 Trainingsdaten gab immer die Rate \textit{Standard} aus - welche zu 97\% auftritt. 


~\newline Von den (zuletzt) nicht erkannten Daten besitzen 75\% die Rate \textit{Negotiated}.

~\newline Als Nebenergebnis ist zu nennen, das die Trainingsverfahren meist nach ca. 100 Epochen aufhören, weil keine weiteren Änderungen in der Genauigkeit erzielt werden.
\newpage
\section{Fahrtenaufkommen}
\label{sec:RidesPred}
Als nächstes Beispiel wird die Prognose des Fahrtenaufkommens behandelt. 

~\newline Diese Prognose stellt die Erste für aggregierte Daten dar, und besitzt somit wesentlich weniger Trainingsdaten.

~\newline Eine weitere Schwierigkeit für das Modell besteht darin, das die Testdaten aus der Menge der Trainingsdaten entfernt wurden, und somit die Gruppierungen der Testdaten in dieser Form nicht vorliegen. 

Das Modell muss also, um die Fahrten des 31. August um 12:00 vom JFK-Airport vorherzusagen,welche in dieser Kombination nicht im Training vorkommen, einen Transfer auf unbekannte Daten leisten. Das Neuronale Netz kann sich in diesem Fall nicht \textit{erinnern}.

~\newline Eine letzte Schwierigkeit für dieses Modell stellt die große Reichweite der Werte dar: Während es in den Äußeren Zonen häufig zu wenigen oder keinen Fahrten kommt, werden Börsenviertel und Flughäfen stark frequentiert. 

Hierbei gibt es sowohl in den Orten als auch in den kalendarischen Daten starke Ausschläge, welche innerhalb der gruppierten Daten zu einer breiten Streuung führt.
\paragraph{Zielsetzung} ~\newline
Ziel des Modells ist es, für einen gegebenen Ort und eine gegebene Stunde eines Tages die Anzahl der \textbf{ausgehenden} Fahrten vorherzusagen. 

~\newline Dieses Modell hilft dem Unternehmen, seine Taxi-Kontingente strategisch zu verteilen bzw. kann dem Taxifahrer helfen, vor einer Rushhour am richtigen Taxistand einzutreffen. 
\paragraph{Versuchsaufbau} ~\newline
Die Taxifahrten liegen in aggregierter Form vor: Sie wurden nach Datum, Tageszeit auf Stunde gerundet und Startort gruppiert. Die daraus Resultierenden Trainingsdaten sind Wertepaare aus der Anzahl der Fahrten, Ort, Stunde und Datum. 

Die Gruppierungskriterien werden in R als Faktoren repräsentiert. 

Ausgabe des Modells ist eine Schätzung der Fahrten, welche auf eine Ganzzahl gerundet wird. 

\paragraph{Netzdefinition} ~\newline
Für die endgültige Netzdefinition wurde ein einzelner Layer mit 300 Knoten und der \textit{tanh}-Aktivierungsfunktion gewählt. Die Ausgabe erfolgt über die \textit{Linear}-Funktion.

~\newline Die Lernrate wurde auf 15\% gesetzt und als Optimierungsfunktion Stochastic Gradient Descent gewählt. Es wurde ein Verfall von 5\% gewählt. Es werden jeweils 500 Epochen durchgeführt. 
\paragraph{Tuning und Verbesserung} ~\newline
Die Prognose des Fahrtenaufkommen hat in den ersten Versuchen mit zwei Hidden Layern keine Ergebnisse erzielt (genau genommen negative $r^2$-Werte \footnote{negative $r^2$-Werte bedeuten, das eine Gerade bessere Werte erzielt, als das Modell}). Das erzeugte Modell gab in jedem Fall den Mittelwert der Fahrten aus, die Gewichte innerhalb des Modells hatten verschwindend geringe Werte und der Mittelwert wurde als Bias addiert. 


~\newline Hierfür gibt es zwei mögliche Erklärungen: Die erste ist Overfitting. Die zweite ist eine mögliche, noch zu geringe Komplexität bzw. fehlende Features. 

Um das Problem zu analysieren wurden dahingehend verschiedene Netzparameter durchgespielt, von [10,10] bis [1000,1000]-Netzen wurde eine große Bandbreite getestet. Auch die Veränderung der Aktivierungsfunktionen zu Sigmoid, Tanh, Softmax und Linear, bzw. Kombinationen dieser, erzeugte keine Ergebnisse. 

~\newline Die ersten Ergebnisse wurden erzielt, als die zweite versteckte Schicht entfernt wurde. Das neue Modell mit einer einzelnen, 100 Knoten großen Schicht zeigte das zu erwartende, trainierbare verhalten. Hier zeigten größere Trainingsdaten sowie mehr Epochen eine Positive Wirkung auf die erstmals positive Genauigkeit. Ebenso zeigten unterschiedliche Aktivierungsfunktionen verschiedene Ergebnisse (Linear sehr schlechte, Softmax und Sigmoid gute, Tanh sehr gute). 

~\newline Dieses Verhalten legt nahe, das es sich um eine Art von Overfitting gehandelt hat. 

~\newline Die besseren Ergebnisse der Tanh-Aktivierungsfunktion gegenüber der Sigmoid- und Softmax-Funktion sind voraussichtlich auf das Verhalten um die Nullstelle zurückzuführen: Während die $sig(0)=0.5$ ist, gilt $tanh(0)=0$. Somit werden Null-Werte, wie sie in den Faktorisierten Werten (z.B. Ort) häufig auftreten, besser abgebildet und werden unabhängig vom angelegten Gewicht nicht in die weiteren Berechnungen aufgenommen. 

Unter Verwendung der Sigmoid-Funktion werden bei vielen Epochen und Trainingsdaten zwar ebenfalls akzeptable Ergebnisse erzielt, dennoch liegt das i.A. daran, dass die Gewichte der Faktorisierten Daten gegen Null reduziert werden. Dies führt dazu, das faktorisierte Features nicht (stark) in die Prognose aufgenommen werden, und durch den \textit{Wegfall} der Features ein schwächeres Modell erzeugt wird. 

~\newline Eine Verbesserung der Genauigkeit hat sich ebenfalls durch das Erhöhen der Neuronenanzahl sowie der Anzahl der Epochen ergeben. Die in Netzdefinition genannten Einstellungen ergaben hierbei die kleinsten Werte mit der höchsten erzielten Genauigkeit.

~\newline Eine potenzielle Verbesserung würde eine komplexere Netzdefinition darstellen, welche zwei (oder drei) parallele Schichten besitzt: Eine für die numerischen Daten mit der Sigmoid- oder Softmax-Funktion sowie eine getrennte Schicht für die faktorisierten Daten. 
~\newline Was (meiner Meinung) nach ebenfalls eine wesentliche Verbesserung darstellen kann ist die Aufnahme eines zweiten Jahres in die Trainingsdaten.
\paragraph{Ergebnisse} ~\newline
Die unter Netzdefinition genannten Optionen erzielten folgende Werte:

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=0.95\linewidth]{Bilder/FahrtenErgebnisse}
		\caption[Ergebnisse der Trinkgeldprognose]{Ergebnisse der Fahrten-Prognose}
		\label{fig:RidesErg}
	\end{center}
\end{figure}

Dies stellt zwar nicht die besten Ergebnisse dar, dennoch stellen die unter \textbf{Tuning} vorgestellten Maßnahmen die wichtigsten praktischen Erkenntnisse dieser Arbeit dar. 

~\newline Bei Eintausend Trainingsdaten gibt das Modell lediglich den Mittelwert aus - es liegen noch zu wenig Trainingsdaten vor. Bei Fünf- und Zehntausend liegt zunächst ein starker Einbruch vor, was darauf zurückzuführen ist, dass sich das Modell an den (wenigen) Trainingsdaten ausrichtet, die inhaltlich zu weit entfernt sind von den tatsächlichen Testdaten (Es könnten z.B. keine Daten für den Oktober, oder keine Daten für Nachtfahrten ins Training eingeflossen sein).

~\newline Werden die Ergebnisse nicht gerundet (auf \textit{ganze Fahrten}) so liegen die $r^2$-Werte ca. 2\% höher (in allen Versuchen).
\newpage
\section{Passagieranzahl}
\label{sec:PasPred}
Ein weiteres Beispiel ist die Vorhersage der Anzahl der Passagiere, welche an einer Fahrt teilnehmen. 

Dieser Use-Case ist eher für technische Belange interessant, denn die Verteilung der Passagieranzahl\footnote{Es handelt sich hierbei um die ungefilterten Daten} über die Fahrten stellt eine Besonderheit dar: 


\begin{figure}[h]
	\begin{center}
		\includegraphics[width=0.8\linewidth]{Bilder/PassagierVerteilung}
		\caption[Verteilung der Passagieranzahl]{Verteilung der Passagieranzahl über alle Fahrten}
		\label{fig:PassagierVerteilung}
	\end{center}
\end{figure}


Wie zu erkennen ist, besitzen die meisten Fahrten einen einzelnen Passagier. Diese machen Rund 70\% der Fahrten aus.

Von den verbleibenden Fahrten machen Zwei-Passagier-Fahrten ca. 60\% aus.  Dies hat sich im Verlauf der Entwicklung als überaus herausfordernd herausgestellt. 
\paragraph{Zielsetzung} ~\newline
Ziel des Modells ist es, für einen gegebenen Ort, Datum und Stunde einer Fahrt die Anzahl der Passagiere vorherzusagen. 
 
\paragraph{Versuchsaufbau} ~\newline
Für diesen Use-Case wurden verschiedene Versuche durchgeführt. Gemeinsamkeit bilden die Eingegebenen Daten: Datum, Tageszeit und Ort des Fahrtbeginns. 
\begin{enumerate}
	\item In \textit{Variante 1} wurde das Modell mit Regression erstellt. 
	\item In \textit{Variante 2} wurde das Modell für Multiklassen-Klassifizierung erstellt.
	\item In \textit{Variante 3} wurden Einzelfahrten gefiltert und ein Regressionsmodell erstellt. 
	\item In \textit{Variante 4} wurden ebenfalls Einzelfahrten gefiltert und ein Multiklassen-Modell generiert. 
\end{enumerate}
Ausgabe war, abhängig von der Variante, die Anzahl der Fahrten als Ganzzahl (1 \& 3) oder Klasse (2 \& 4). 

Es wurden verschiedene Netzdefinitionen durchgespielt (Was Tiefe, Schichtgröße und Aktivierungsfunktionen angeht), dennoch erzielten diese für alle 4 Varianten die selben Ergebnisse:
\paragraph{Ergebnisse} ~\newline
Variante 1 \& 2 erreichten, bei größeren Trainingsmengen (ca. 10000), eine Genauigkeit von 70\% \footnote{Variante 1 nur bei einer Rundung auf Ganzzahl, ansonsten etwa 65\%}. Während dies Objektiv ein akzeptabler Wert ist, gibt das Modell für jede Eingabe stets eine \textit{Ein-Personen-Fahrt} aus. Diese Annahme stimmt in 70\% aller Fälle. 

~\newline Variante 3 \& 4 zeigten dieselbe Schwäche für \textit{Zwei-Personen-Fahrten}. Für kleinere Trainingsdaten wurden Modelle erzeugt, welche andere Ausgaben erzeugten, allerdings wurden mit zunehmenden Iterationen und Trainingsdaten wieder nur die statistisch häufigsten Werte ausgegeben. 

~\newline Die dabei entstehenden Modelle zeichnen sich alle durch verschwindend geringe Gewichte aus. Die einzige Änderung geschieht innerhalb des Bias, welcher in beiden Modellen (nach Abschluss des Trainings) dem Ergebnis entspricht.

~\newline Da auch die Verwendung von der $Tanh$-Funktion und der Linear-Funktion in keinem befriedigendem Maße Ergebnisse zeigte (Welche sich für stark von Faktoren abhängige Schichten besser zu eignen scheinen, Siehe \ref{sec:RidesPred}), ist anzunehmen, dass elementare Features fehlen. Ein oder mehrere ausschlaggebende Kriterien, um die Passagieranzahl zu ermitteln, wurde innerhalb der Trainingsdaten noch nicht abgebildet/berücksichtigt. 

~\newline Ein Nebenergebnis des Versuches ist der direkte Vergleich der Geschwindigkeiten: Variante 1 und 3, sowie Variante 2 und 4 verhielten sich in ihrer Trainingsdauer jeweils Analog. 

Die Multiklassen-Varianten benötigten aber ca. die 3 fache Zeit ihrer Regressions-Gegenstücke.

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=0.8\linewidth]{Bilder/PassagierErgebnisse}
		\caption[Ergebnisse der Passagiervorhersage]{Ergebnisse der Passagiervorhersage (Variante 2)}
		\label{fig:PasErg}
	\end{center}
\end{figure}
 
 
 Die oben stehenden Ergebnisse in Abbildung \ref{fig:PasErg} entsprechen den Zeiten von 250 Iterationen bei einem einzelnen $tanh$-Layer mit 250 Knoten und einer Multiklassen-Ausgabe. 
\newpage
\section{Umsatzvorhersage}
\label{sec:RevPred}
Als letztes Beispiel wird die Umsatzvorhersage behandelt. Dieses stellt für das Unternehmen offensichtlich den wichtigsten Use-Case dar.Sie gibt dem Unternehmen nicht nur eine Übersicht über den ist-Zustand, sondern zeigt ebenfalls detailliert an welchen Punkten noch gearbeitet werden muss. 

Ein gut funktionierendes Modell kann ggfs. auch zur Prognose von Änderungen erweitert werden.
\paragraph{Zielsetzung} ~\newline
Ziel des Modells ist es, für einen gegebenen Ort und eine gegebene Stunde eines Tages Summe der Fahrtenkosten auszugeben. 

\paragraph{Versuchsaufbau} ~\newline
Der Gesamtumsatz wird aus den Einzelfahrten aufsummiert: Sie wurden nach Datum, Tageszeit auf Stunde gerundet und Startort gruppiert. Die daraus Resultierenden Trainingsdaten sind Wertepaare aus dem Gesamtumsatz, Ort, Stunde und Datum. 

Die Gruppierungskriterien werden in R als Faktoren repräsentiert. 

Ausgabe des Modells ist eine Schätzung des Umsatzes, welche auf zwei Nachkommastellen gerundet wird. 

\paragraph{Netzdefinition} ~\newline

\paragraph{Versuchsaufbau} ~\newline

\paragraph{Netzdefinition} ~\newline

\paragraph{Tuning und Verbesserung} ~\newline

\paragraph{Ergebnisse} ~\newline

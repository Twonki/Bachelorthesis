\newpage
\label{Prognosen}
\section{Trinkgeldprognose}
\label{sec:TipPred}
Als erstes Beispiel wird die Vorhersage des gegebenen Trinkgeldes behandelt. 

~\newline Dies stellt zwar nicht unbedingt ein für das Unternehmen hochgradig relevantes Thema dar, bietet jedoch einen guten Einstieg in das Thema Regression mit Hilfe von \textit{Deep Learning}:

~\newline Es ist anzunehmen, dass Passagiere nach einem gewissen Schema Trinkgeld geben, etwa um Beträge aufzurunden oder eine schnelle Fahrt zu \textit{belohnen}. Ebenso kann es Kriterien geben, welche nicht innerhalb der Daten erfasst sind, wie die Stimmung der Passagiere oder die Freundlichkeit des Fahrers. Genauso treten eventuell Kriterien auf, welche zu einem Entfall des Trinkgeldes führen, eine lange Fahrt, eine Panne, oder ein Taxifahrer der \textit{Extrarunden dreht}. 

~\newline Dennoch lassen sich diese potenziellen Kriterien schwer in einen anwendbaren Katalog zusammenfassen, nachdem man logisch das Trinkgeld erschließen kann. Vor diesem Hintergrund bietet sich die Verwendung eines tiefen Neuronalen Netzes an: 

Die erste versteckte Schicht extrahiert (uns unbekannte, nicht genauer definierte) Kriterien automatisch, und die zweite Schicht gewichtet diese. 
\paragraph{Zielsetzung} ~\newline
Das Modell soll vorhersagbare Attribute erhalten, um für eine geplante Fahrt das Trinkgeld zu schätzen. 

Ziel ist es eine gute Prognose mit realistischen, d.h. abschätzbaren Features zu erzeugen. 

~\newline Aus unternehmerisches Sicht ist dieser Use-Case relevant, da Fahrer voraussichtlich die Fahrten mit höherem Trinkgeld bevorzugen werden, obwohl sich diese nicht mit dem größten Nutzen des Unternehmens decken müssen. 
\paragraph{Versuchsaufbau} ~\newline
Die Fahrten liegen in gefilterter, aber nicht weiter aufbereiteter Form vor. 

Als Eingabefeatures werden die Fahrtdauer in Minuten, der Start- und Ziel-Ort, die Kosten der Fahrt, die gefahrene Strecke und die Anzahl der Passagiere gewählt. 

Die Ausgabe ist eine Schätzung des Trinkgeldes in Dollar.
\paragraph{Netzaufbau und Einstellungen} ~\newline
Das neuronale Netz wurde mit zwei Schichten á 100 Knoten definiert. Die Schichten sind vollvermascht und verwenden beide die Sigmoidfunktion. Als Ausgabefunktion wurde \textit{Linear} gewählt.

~\newline Die Lernrate wurde auf 5\% gesetzt und als Optimierungsfunktion Stochastic Gradient Descent gewählt. Es werden jeweils 500 Epochen durchgeführt. 
\paragraph{Tuning und Verbesserung} ~\newline
Wesentliche Unterschiede in der Genauigkeit dieses Beispiels verbucht die Auswahl der Features:
\begin{itemize}
	\item Modelle, welche nicht die Gesamtkosten der Fahrt als Eingabe erhalten, erzielen nur Genauigkeiten von 75\%.
	\item Ein Modell, welches sich auf ausschließlich die Kosten der Fahrt stützt, erzielte eine Genauigkeit von ca. 40\%. 
	\item Werden die im Versuchsaufbau genannten Features um (grobe) Wetterdaten und eine Tageszeit erweitert, verbessert sich die Genauigkeit des Modells auf bis zu 98\%. 
	\item Werden die im Versuchsaufbau genannten Features um die Passagieranzahl gekürzt wird nur eine Genauigkeit von ca. 80\% erzielt - die Passagieranzahl scheint also ein wesentliches Feature darzustellen.
	\item Weitere Features, welche sich auf den Preis beziehen (z.B. die Rate der Fahrt, Steuerliche Zulagen, diverse Aufschläge), welche bereits im Gesamtpreis enthalten sind, bringen keine Veränderung der Genauigkeit. 
\end{itemize} 
~\newline Im Rahmen der Zielsetzung wurden aber lediglich die unter dem Versuchsaufbau gewählten Attribute verwendet. Die Vorhersage des Wetters gestaltet sich weitestgehend schwierig für ein Taxiunternehmen bzw. den Fahrer. 

~\newline Weitere Unterschiede erzeugten Veränderungen in der Netzdefinition: 

Eine Verkleinerung einer der beiden Schichten unter 50 Knoten führte zu drastisch schlechteren Ergebnissen (max. 60\% Genauigkeit). 

Eine Vergrößerung der Schichten über 100 Knoten führte zu keinem Gewinn an Genauigkeit, jedoch zu längeren Laufzeiten (Ein Trainingsdurchlauf mit je 200 Knoten dauert ca. 4 mal so lange).

~\newline Eine Verwendung der Aktivierungsfunktion \textit{tanh} führte zu keinen Unterschieden, eine Verwendung der Softmax-Aktivierungsfunktion führte zu einer um ca. 20\% längeren Laufzeit und ähnlichen Genauigkeiten. 
\paragraph{Ergebnisse} ~\newline
Die folgenden Ergebnisse wurden mithilfe der unter \textbf{Netzaufbau und Einstellungen} genannten Optionen erzielt:

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=0.95\linewidth]{Bilder/TrinkgeldErgebnisse}
		\caption[Ergebnisse der Trinkgeldprognose]{Ergebnisse der Trinkgeldprognose}
		\label{fig:TipErg}
	\end{center}
\end{figure}

\todo{"Minifazit" hier? Kurze bewertung oder einfach so stehen lassen?}
\newpage
\section{Ratenerkennung}
\label{sec:RatePred}
Als zweites Beispiel wird die Erkennung der Fahrrate behandelt. Dieser Fall ist weitestgehend Trivial, wurde dennoch als einfache Referenz für Multiklassen-Klassifikation aufgenommen. 

~\newline Im Gegensatz zur Trinkgeldprognose sind die Kriterien, nach welchen sich die Fahrtkosten berechnen, klar dokumentiert: Je nach Rate kostet jede Meile und jede Minute einen bestimmten Betrag. Zusätzlich kommt je nach Gebiet (z.B. JFK-Airport) ein Aufschlag hinzu. Dahingehend lässt sich diese Formel zur Erkennung der Rate umformen.

~\newline Interessant wird dieser Use-Case vor dem Hintergrund, das die Raten bzw. ihre zugehörigen Verrechnungssätze nicht innerhalb der Daten auftreten, und das Modell erkennen muss, welche Beträge Aufschläge sind, und welche Beträge die Raten ausmachen. 

Das Modell soll also in diesem Fall einen für den Menschen eindeutigen, klar nachvollziehbaren Sachverhalt reproduzieren. 
\paragraph{Versuchsaufbau} ~\newline
Die Fahrten liegen in gefilterter, aber nicht weiter aufbereiteter Form vor. 

Als Eingabefeatures werden die Fahrtdauer in Minuten, der Start- und Ziel-Ort, die Kosten der Fahrt, die gefahrene Strecke sowie die Anzahl der Passagiere gewählt. 

Die Ausgabe ist die Rate der Taxifahrt als Dictionary-ID.
\paragraph{Netzdefinition} ~\newline
Das neuronale Netz wurde mit zwei Schichten á 100 Knoten definiert. Die Schichten sind vollvermascht und verwenden beide die Sigmoidfunktion. Als Ausgabefunktion wurde \textit{Softmax} gewählt.

~\newline Die Lernrate wurde auf 5\% gesetzt und als Optimierungsfunktion Stochastic Gradient Descent gewählt. Es werden jeweils 250 Epochen durchgeführt. 
\paragraph{Tuning und Verbesserung} ~\newline
Innerhalb der Ratenerkennung ließen sich wenig Verbesserungen vornehmen: Grund hierfür ist die bereits anfänglich hohe Genauigkeit. 

Eine Verbesserung der Geschwindigkeit lässt sich mit einem kleineren Netz erzielen. Eine Netzdefinition mit 60 und 10 Knoten in den Hidden Layern erzielte bei größeren Trainingsmengen ebenfalls eine Genauigkeit von 99\%, was für die meisten Anwendungen ausreichend ist. Es benötigt allerdings nur ca. ein Fünftel der Zeit fürs Training.
\paragraph{Ergebnisse} ~\newline
Die unter Netzdefinition genannten Optionen erzielten folgende Werte:

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=0.95\linewidth]{Bilder/RatenErgebnisse}
		\caption[Ergebnisse der Trinkgeldprognose]{Ergebnisse der Ratenerkennung}
		\label{fig:RateErg}
	\end{center}
\end{figure}

~\newline Ein wichtiges Teilergebnis ist die Veränderung des ersten Versuches mit 1000 Trainingsdaten zu dem mit 5000 Trainingsdaten: 
~\newline Zwar steigt die Genauigkeit nur minimal, dennoch werden erst ab 5000 Trainingsdaten die weniger vertretenen Daten korrekt erkannt. Das Modell für 1000 Trainingsdaten gab immer die Rate \textit{Standard} aus - welche zu 97\% auftritt. 


~\newline Von den (zuletzt) nicht erkannten Daten besitzen 75\% die Rate \textit{Negotiated}.

~\newline Als Nebenergebnis ist zu nennen, das die Trainingsverfahren meist nach ca. 100 Epochen aufhören, weil keine weiteren Änderungen in der Genauigkeit erzielt werden.
\newpage
\section{Fahrtenaufkommen}
\label{sec:RidesPred}
Als nächstes Beispiel wird die Prognose des Fahrtenaufkommens behandelt. 

~\newline Diese Prognose stellt die Erste für aggregierte Daten dar, und besitzt somit wesentlich weniger Trainingsdaten.

~\newline Eine weitere Schwierigkeit für das Modell besteht darin, das die Testdaten aus der Menge der Trainingsdaten entfernt wurden, und somit die Gruppierungen der Testdaten in dieser Form nicht vorliegen. 

Das Modell muss also, um die Fahrten des 31. August um 12:00 vom JFK-Airport vorherzusagen,welche in dieser Kombination nicht im Training vorkommen, einen Transfer auf unbekannte Daten leisten. Das Neuronale Netz kann sich in diesem Fall nicht \textit{erinnern}.

~\newline Eine letzte Schwierigkeit für dieses Modell stellt die große Reichweite der Werte dar: Während es in den Äußeren Zonen häufig zu wenigen oder keinen Fahrten kommt, werden Börsenviertel und Flughäfen stark frequentiert. 

Hierbei gibt es sowohl in den Orten als auch in den kalendarischen Daten starke Ausschläge, welche innerhalb der gruppierten Daten zu einer breiten Streuung führt.
\paragraph{Zielsetzung} ~\newline
Ziel des Modells ist es, für einen gegebenen Ort und eine gegebene Stunde eines Tages die Anzahl der \textbf{ausgehenden} Fahrten vorherzusagen. 

~\newline Dieses Modell hilft dem Unternehmen, seine Taxi-Kontingente strategisch zu verteilen bzw. kann dem Taxifahrer helfen, vor einer Rushhour am richtigen Taxistand einzutreffen. 
\paragraph{Versuchsaufbau} ~\newline
Die Taxifahrten liegen in aggregierter Form vor: Sie wurden nach Datum, Tageszeit auf Stunde gerundet und Startort gruppiert. Die daraus Resultierenden Trainingsdaten sind Wertepaare aus der Anzahl der Fahrten, Ort, Stunde und Datum. 

Die Gruppierungskriterien werden in R als Faktoren repräsentiert. 

Ausgabe des Modells ist eine Schätzung der Fahrten, welche auf eine Ganzzahl gerundet wird. 

\paragraph{Netzdefinition} ~\newline
Für die endgültige Netzdefinition wurde ein einzelner Layer mit 300 Knoten und der \textit{tanh}-Aktivierungsfunktion gewählt. Die Ausgabe erfolgt über die \textit{Linear}-Funktion.

~\newline Die Lernrate wurde auf 15\% gesetzt und als Optimierungsfunktion Stochastic Gradient Descent gewählt. Es wurde ein Verfall von 5\% gewählt. Es werden jeweils 500 Epochen durchgeführt. 
\paragraph{Tuning und Verbesserung} ~\newline
Die Prognose des Fahrtenaufkommen hat in den ersten Versuchen mit zwei Hidden Layern keine Ergebnisse erzielt (genau genommen negative $r^2$-Werte \footnote{negative $r^2$-Werte bedeuten, das eine Gerade bessere Werte erzielt, als das Modell}). Das erzeugte Modell gab in jedem Fall den Mittelwert der Fahrten aus, die Gewichte innerhalb des Modells hatten verschwindend geringe Werte und der Mittelwert wurde als Bias addiert. 


~\newline Hierfür gibt es zwei mögliche Erklärungen: Die erste ist Overfitting. Die zweite ist eine mögliche, noch zu geringe Komplexität bzw. fehlende Features. 

Um das Problem zu analysieren wurden dahingehend verschiedene Netzparameter durchgespielt, von [10,10] bis [1000,1000]-Netzen wurde eine große Bandbreite getestet. Auch die Veränderung der Aktivierungsfunktionen zu Sigmoid, Tanh, Softmax und Linear, bzw. Kombinationen dieser, erzeugte keine Ergebnisse. 

~\newline Die ersten Ergebnisse wurden erzielt, als die zweite versteckte Schicht entfernt wurde. Das neue Modell mit einer einzelnen, 100 Knoten großen Schicht zeigte das zu erwartende, trainierbare verhalten. Hier zeigten größere Trainingsdaten sowie mehr Epochen eine Positive Wirkung auf die erstmals positive Genauigkeit. Ebenso zeigten unterschiedliche Aktivierungsfunktionen verschiedene Ergebnisse (Linear sehr schlechte, Softmax und Sigmoid gute, Tanh sehr gute). 

~\newline Dieses Verhalten legt nahe, das es sich um eine Art von Overfitting gehandelt hat. 

~\newline Die besseren Ergebnisse der Tanh-Aktivierungsfunktion gegenüber der Sigmoid- und Softmax-Funktion sind voraussichtlich auf das Verhalten um die Nullstelle zurückzuführen: Während die $sig(0)=0.5$ ist, gilt $tanh(0)=0$. Somit werden Null-Werte, wie sie in den Faktorisierten Werten (z.B. Ort) häufig auftreten, besser abgebildet und werden unabhängig vom angelegten Gewicht nicht in die weiteren Berechnungen aufgenommen. 

Unter Verwendung der Sigmoid-Funktion werden bei vielen Epochen und Trainingsdaten zwar ebenfalls akzeptable Ergebnisse erzielt, dennoch liegt das i.A. daran, dass die Gewichte der Faktorisierten Daten gegen Null reduziert werden. Dies führt dazu, das faktorisierte Features nicht (stark) in die Prognose aufgenommen werden, und durch den \textit{Wegfall} der Features ein schwächeres Modell erzeugt wird. 

~\newline Eine Verbesserung der Genauigkeit hat sich ebenfalls durch das Erhöhen der Neuronenanzahl sowie der Anzahl der Epochen ergeben. Die in Netzdefinition genannten Einstellungen ergaben hierbei die kleinsten Werte mit der höchsten erzielten Genauigkeit.

~\newline Eine potenzielle Verbesserung würde eine komplexere Netzdefinition darstellen, welche zwei (oder drei) parallele Schichten besitzt: Eine für die numerischen Daten mit der Sigmoid- oder Softmax-Funktion sowie eine getrennte Schicht für die faktorisierten Daten. 
~\newline Was (meiner Meinung) nach ebenfalls eine wesentliche Verbesserung darstellen kann ist die Aufnahme eines zweiten Jahres in die Trainingsdaten.
\paragraph{Ergebnisse} ~\newline
Die unter Netzdefinition genannten Optionen erzielten folgende Werte:

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=0.95\linewidth]{Bilder/FahrtenErgebnisse}
		\caption[Ergebnisse der Trinkgeldprognose]{Ergebnisse der Fahrten-Prognose}
		\label{fig:RidesErg}
	\end{center}
\end{figure}

Dies stellt zwar nicht die besten Ergebnisse dar, dennoch stellen die unter \textbf{Tuning} vorgestellten Maßnahmen die wichtigsten praktischen Erkenntnisse dieser Arbeit dar. 

~\newline Bei Eintausend Trainingsdaten gibt das Modell lediglich den Mittelwert aus - es liegen noch zu wenig Trainingsdaten vor. Bei Fünf- und Zehntausend liegt zunächst ein starker Einbruch vor, was darauf zurückzuführen ist, dass sich das Modell an den (wenigen) Trainingsdaten ausrichtet, die inhaltlich zu weit entfernt sind von den tatsächlichen Testdaten (Es könnten z.B. keine Daten für den Oktober, oder keine Daten für Nachtfahrten ins Training eingeflossen sein).

~\newline Werden die Ergebnisse nicht gerundet (auf \textit{ganze Fahrten}) so liegen die $r^2$-Werte ca. 2\% höher (in allen Versuchen).
\newpage
\section{Passagieranzahl}
\label{sec:PasPred}

\todo{Vorher \textit{Flat Learning} auf die Menge ohne Einzelfahrten testen, nicht das es noch gute Ergebnisse gibt}
\paragraph{Zielsetzung} ~\newline

\paragraph{Versuchsaufbau} ~\newline

\paragraph{Netzdefinition} ~\newline

\paragraph{Tuning und Verbesserung} ~\newline

\paragraph{Ergebnisse} ~\newline

\newpage
\section{Umsatzvorhersage}
\label{sec:RevPred}
\paragraph{Zielsetzung} ~\newline

\paragraph{Versuchsaufbau} ~\newline

\paragraph{Netzdefinition} ~\newline

\paragraph{Tuning und Verbesserung} ~\newline

\paragraph{Ergebnisse} ~\newline

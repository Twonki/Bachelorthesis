\section{Machine Learning im SQL-Server 2017}
\label{sec:MLSQL} \label{sec:MachineLearning}
Innerhalb dieses Abschnittes befinden sich Code-Beispiele zur Umsetzung der in Kapitel \ref{cha:Theorie} vorgestellten Algorithmen. 

Es werden im Folgenden kurz die Einbindung der R-Skripte in TSQL behandelt, anschließend werden nur die R-Skripte für die einzelnen Punkte erläutert.

\paragraph{Verwendung von R im SQL-Server}
Um R im SQL-Server zu benutzen wird die Stored Procedure \textit{sp\_execute\_external\_script} benötigt. Im Folgenden ein einfaches Beispiel: ~\newline

\begin{lstlisting}[language=SQL]
	EXECUTE sp_execute_external_script
	@language = N'R',
	@script = N' 
		mytextvariable <- c("hello", " ", input_data);
		OutputDataSet <- as.data.frame(mytextvariable);',
	@input_data = N' SELECT name FROM readers'
	WITH RESULT SETS (([Greetings] char(20) NOT NULL));
\end{lstlisting}

Hierbei wird in Zeile 2 zunächst die Sprache als Parameter übergeben, in Zeile 4 wird innerhalb des R Skriptes ein Begrüßungs-String erstellt, welcher in Zeile 5 als Ausgabe wiedergeben wird.

In Zeile 6 wird die Inputvariable definiert, an dieser Stelle sind SQL Befehle und gültige T-SQL Variablen möglich. Es können beliebig viele Inputvariablen definiert werden. 

In Zeile 7 wird die Ausgabe in Tabellenform überführt. Diese Zeile ist nicht zwingend notwendig.  

~\newline Dieses Schema bleibt allen Skript-Aufrufen gleich. Im Folgenden werden nur die R-Skripte vorgestellt.
\subsection{Lineare Regression}
Für die diese Form der Regression gelten innerhalb des Paketes MicrosoftML folgende Bedingungen: ~\newline
\begin{enumerate}
	\item Strings und kalendarische Daten müssen über einen Faktor realisiert werden 
	\item Der Ausgabewerte ist eine reelle Zahl 
\end{enumerate}

Um ein Modell für die lineare Regression zu erstellen, sind in R nur wenige Zeilen notwendig: ~\newline
\begin{lstlisting}[language=R]
	formel <- C ~ A+B;
	model <- rxLinMod(formula=formel, data=TrainingsData);
	serializedModel <- data.frame(payload = as.raw(serialize(model, connection=null)));
\end{lstlisting}

In der ersten Zeile wird zunächst eine allgemeine Formel definiert. Diese Formel ist zu interpretieren als $f: (A~x~B)\rightarrow C $ , das '+' ist hierbei nicht als Addition zu verstehen.

In Zeile 2 wird das Modell mithilfe der Bibliothek RevoscaleR und dem Methodenaufruf rxLinMod erstellt \textbf{und} Trainiert. Als Parameter werden die Formel und die Trainingsdaten benötigt. 

In der dritten Zeile findet eine Serialisierung des Modells statt - dies ist nicht notwendig für eine direkte Verwendung, ermöglicht allerdings das speichern des Modells innerhalb des SQL-Servers als Blob.  

Um das Modell zu benutzen reichen ebenfalls wenige Zeilen R-Skript: \newline

\begin{lstlisting}[language=R]
	model <- unserialize(as.raw(serializedModel)); 
	C <- rxPredict(model,data.frame(TestData));
\end{lstlisting}

Hierbei wird zunächst in Zeile 1 das serialisierte Modell wieder nutzbar gemacht. 

In Zeile 2 wird die Methode \textit{rxPredict} der RevoScaleR-Bibliothek aufgerufen, welche aus den zu testenden Daten und dem Model eine Prognose erstellt. 
\subsection{Klassifikation}
Für die Klassifikation mit RevoscaleR gelten folgende Bedingungen: ~\newline

\begin{enumerate}
	\item Die Klasse stellt einen Faktor mit Level 2 dar.
	\item Der Ausgabewerte ist eine Wahrscheinlichkeit, mit der die Ausprägung positiv ausfällt
	\item Es kann gleichzeitig nur eine Klasse überprüft werden
\end{enumerate}

Der R-Code verhält sich parallel zum Code der linearen Regression:

\begin{lstlisting}[language=R]
	formel <- rain ~ temperature+humidity;
	logitmodel <- rxLogit(formula = form, data = TrainingsData);
	rainPropability <- rxPredict(model, data.frame(TestData));
\end{lstlisting}

Als Beispiel wurde hierbei die Voraussage gewählt, ob es regnet anhand von Temperatur und Luftfeuchtigkeit.
\subsection{Neuronale Netze}
Es ist Möglich, die im Abschnitt \ref{sec:NN} vorgestellten Konzepte direkt in R umzusetzen. Ein gutes Tutorial liefert hierbei \cite{SelbyNN}, welcher eine Schritt-Für-Schritt Anleitung und Erklärung bietet ein eigenes Neuronales Netz zu entwerfen. Das Tutorial von Selby setzt einen ähnlichen Blogeintrag von Denny Britz (Siehe \cite{DennyNN}) in R um. 

Innerhalb dieser Arbeit wird allerdings das Paket \textit{MicrosoftML} verwendet.

\paragraph{Netz-Definition} ~\newline
Eine der wichtigsten Einstellung stellt die Definition des Neuronalen Netzes dar. Für diese wird innerhalb der Microsoft-Umgebung (Innerhalb des ML-Servers, Azure und R-Services) einheitlich eine Definition in \textit{Net\#} verwendet. Diese Notation definiert  das gesamte Neuronale Netz, und stellt einen einheitlichen und übertragbaren Standard in der Microsoft Umgebung dar. Ein einfaches Beispiel: ~\newline

\begin{lstlisting}[language=R]
 netDefinition <- ("
 	input Data auto;
 	hidden Hidden[25] sigmoid from Data all;
 	output Result[2] from Hidden all;  
 ")
\end{lstlisting}

In Zeile zwei wird die Eingabeschicht mit dem Namen \textit{Data} und einer automatisch-erkannten Größe erstellt. 

In Zeile drei wird die versteckte Schicht \textit{Hidden} mit 25 Knoten, einer Verbindung zu allen Knoten in Data und der Aktivierungsfunktion \textit{Sigmoid} gewählt. 

In Zeile vier wird die Ausgabeschicht \textit{Result} mit zwei Ausgabeknoten definiert. Es handelt sich um eine Binäre Klassifikation. Die Aktivierungsfunktion wird auf den Standardwert \textit{sigmoid} gesetzt. 

Optional ist es möglich, die Größe eines Layers in der Form [5,5,2] anzugeben. Dies bedeutet, das zunächst zwei Layer mit 5 Knoten und anschließend ein Layer mit 2 Knoten vorliegt, welche eine Einheit bilden. Die anderen Parameter, z.B. die Aktivierungsfunktion, werden für alle Teilschichten übernommen.

~\newline Es werden an ein neuronales Netzwerk innerhalb von net\# folgende Anforderungen gestellt:

\begin{itemize}
	\item Jedes neuronale Netz besitzt mindestens eine Eingabeschichte und genau eine Ausgabeschicht
	\item Die Anzahl der Knoten der Ausgabeschicht entspricht der Klasse des neuronalen Netzes (Ein Ausgabeknoten für Regression, zwei für Binäre Klassifikation, \textit{n} für eine Klassifikation von \textit{n-}Labeln)
	\item Verbindungen müssen azyklisch sein, anders ausgedrückt, sie dürfen keine Kette von Verbindungen bilden, die zurück zum ursprünglichen Quellknoten führen.
	\item Um eine Vorhersage mit dem Modell zu machen, werden bei den Eingabedaten mindestens alle in der Formel angegebenen Features benötigt. 
\end{itemize}

~\newline Nach diesem Schema lassen sich beliebig komplexe neuronale Netze definieren. Es gibt weitere Möglichkeiten, die Netzdefinition anzupassen:

\begin{itemize}
	\item Auswahl von Aktivierungsfunktionen (z.B. Sigmoid, Softmax, Linear)
	\item Deklaration Konvolutionsbündeln, d.h. Schichten definieren, welche sich mit zusätzlichen Gewichten gegenseitig beeinflussen
	\item Deklaration von Selektionsbündeln, d.h. Auswahlkriterien nach welchen die Schichten verknüpft werden
	\item Deklaration von Poolingbündeln, d.h. Schichten und Teilnetze, welche eine ähnliche Funktion erfüllen, allerdings nicht trainiert werden. 
\end{itemize} 

\paragraph{Regression} ~\newline
Ein neuronales Netz mithilfe des Paketes zu erstellen ist ähnlich einfach wie ein normales Modell hierfür:

\begin{lstlisting}[language=R]
netDefinition <- ("
	input Data auto;
	hidden Hidden[25] sigmoid from Data all;
	output Result[1] linear from Hidden all; ")
form <- C ~A+B;
model <- rxNeuralNet(
		formula = form, 
		data = TrainingsData,              
		type = "regression",
		netDefinition = netDefinition,
		numIterations = 100,
		normalize = "yes"
);
\end{lstlisting}

Zunächst wird ein Netz definiert, welches als Ausgabeschicht einen einzelnen Knoten mit linearer Ausgabefunktion besitzt. Anschließend wird die Formel aus dem obigen Beispiel für Lineare Regression definiert, und das Modell mit der Funktion \textit{rxNeuralNet(...)} erstellt. Diese erhält gegenüber anderen Modellen zusätzliche Parameter für die Netzdefinition, die Iterationen und den Typ des neuronalen Netzes. 

Des Weiteren können Einstellungen über die Optimierungsfunktion, Initialisierung der Gewichte, sowie Lerngeschwindigkeit, Verfall und Beschleunigung vorgenommen werden.

\paragraph{Multiclass-Labeling} ~\newline
Um eine Multiklassen-Klassifizerung vorzunehmen benötigt man einen ähnlichen Aufbau:


\begin{lstlisting}[language=R]
netDefinition <- ("
		input Picture auto;
		hidden Hidden[250] sigmoid from Picture all;
		output Species[4] softmax from Hidden all; ")
form <- Species ~Sepal.Length+Sepal.Width+Petal.Length+Petal+Width;

model <- rxNeuralNet(
		formula = form, 
		data = TrainingsData,              
		type = "multiclass",
		netDefinition = netDefinition
);
\end{lstlisting}

Als Beispiel ist die Klassifizierung eines Bildes in eine von 4 Lotus-Spezien gewählt. Zu betonen ist, das die Ausgabe der Vorhersage 5 Werte erzeugt: Einen für die wahrscheinlichste Spezies, und für jede Spezies die Wahrscheinlichkeit.

\subsection{Best Practices: Verwendung der ML-Algorithmen}
Im Rahmen des Praxisteils haben sich im Wesentlichen 3 Best-Practices herauskristalliesiert, welche nun genauer vorgestellt werden. 

\paragraph{Auschnitts-Tabellen und Aggregatstabellen} ~\newline
Im Rahmen des Trainings mussten zufällige Daten ausgewählt werden. Dies wird innerhalb von SQL über die Sortierung einer zufälligen \textit{ID} realisiert. 

~\newline Dieses Verfahren dauert für die vorliegenden Daten (113 Millionen Datensätze) ca. 26 Minuten \footnote{Bei Verwendung eines einfachen Desktop-PCs}. Während diese Zahl bei Modellen, die Stunden trainieren, eher unbedeutend ist, stellte Sie gerade für die ersten "TestModelle" einen Großteil der benötigten Zeit dar. Eine wesentliche Verbesserung ergab sich durch die Erzeugung einer (kleineren) Tabelle, die bereits zufällig Sortiert ist, und ein Training mithilfe dieser Tabelle. 

~\newline Vor Allem für kleinere Modelle, welche lediglich mit wenigen Tausend Daten trainiert wurden, führte dies zu einer markanten Beschleunigung.

~\newline Bei den Modellen welche sich auf aggregierte Daten stützen, fiel dieser Effekt noch größer aus: Eine Aufsummierung des Umsatzes nach Ort und Stunde dauerte ca. eine Stunde. Hierfür wurde ebenfalls eine (redundante) Tabelle erstellt, welche bereits (mehrere) Aggregierte Werte hält. 

\paragraph{ML-Templates} ~\newline
Nach den ersten Schritten mit den Neuronalen Netzen kristallisierte sich ein Muster heraus, welches sich auf alle Use-Cases übertragen lies. Dieses Muster lässt sich mithilfe von 4 SQL-Files darstellen:

\begin{enumerate}
	\item Ein File zur Erstellung einer Prozedur, welche das Neuronale Netz erstellt, trainiert und abspeichert.
	
	Hier findet sich die Netzdefinition, Trainingsparameter und ggfs. eine Aufbereitung der Trainingsdaten.
	\item Ein File zur Erstellung einer Prozedur, welche alle Testdaten mithilfe des Neuronalen Netzes Vorhersagt
	Hier findet sich eine analoge Aufbereitung der Testdaten zu den Trainingsdaten.
	\item Ein File zur Erstellung einer Prozedur, welche die Vorhersage bewertet. Je nach Art des Netzes wird die Genauigkeit berechnet und eine Stichprobe der Vorhersagen genommen.
	
	Diese Prozedur lässt sich soweit vereinfachen, das es jedes beliebige Modell bewertet.
	\item Ein File, welches die Prozeduren ausführt
\end{enumerate}

Mithilfe dieser Templates ließen sich sehr schnell Use-Cases umsetzen und die Modelle sowie Prozeduren waren einheitlich und übersichtlich. 

Für eine reelle Anwendung sollten noch zwei weitere Prozeduren aufgenommen werden: Eine zum \textit{weitertrainieren} eines Modells, sowie eine zur konkreten Vorhersage eines einzelnen Datensatzes. 

\paragraph{Speicherung der Modelle} ~\newline
Für die Organisation, den Vergleich der Modelle und die allgemeine Verwendung wurden die serialisierten Modelle in einer eigenen Tabelle abgespeichert. 

Während diese zunächst nur das Binärfile und den Namen hielten, war dies nicht wirklich hilfreich bei der Wiederverwendung. Deswegen wurde die Tabelle um folgende Eigenschaften erweitert, welche innerhalb der oben genannten Prozeduren mitgesetzt werden:

\begin{enumerate}
	\item Das Erstellungsdatum
	\item Die Art des Modells (Klassifizerung oder Regression)
	\item Die Anzahl der Trainingsdaten
	\item Die Genauigkeit
	\item Einen Kommentar
\end{enumerate}

Die ersten 3 werden hierbei von der Trainings-Prozedur erstellt, die Genauigkeit durch die Bewertungs-Prozedur.

Diese erweiterte Tabelle stellte sich als Wesentlich benutzerfreundlicher heraus und lässt sich über das Template problemlos warten.